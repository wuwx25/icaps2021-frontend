    export let TutorialContent = {Tutorial1: {name: 'Hands-on Introduction to dcss-ai-wrapper: A Dungeon Crawl Stone Soup API for AI Planning',
                                description: '<h3>Description</h3> <p>dcss-ai-wrapper aims to enable the Dungeon Crawl Stone Soup (DCSS) video game to be used as a new benchmark for AI research. While more traditional planning benchmarks exist (i.e. IPC domains) and more traditional RL benchmarks exist (i.e. open-ai gym), it is often difficult to compare an RL agent on IPC domains or a planner on RL domains. DCSS is a complex domain that has built-in support for both automated planning and RL, as well as other properties that make it worthwhile to study.</p><p>Dungeon Crawl Stone Soup is a single-player, free, and open-source rogue-like turn-based video game that consists of a procedurally generated 2-dimensional grid world. To win the game, a player must navigate their character through a series of levels to collect "The Orb of Zot" and then return to the starting location. Along the way, the player encounters a wide variety of monsters and items. Players equip and use items to make themselves stronger or consume them to aid in difficult situations. The DCSS environment is dynamic, stochastic, partially observable, and complex with the number of instantiated actions the player may take reaching into the hundreds.</p><p>dcss-ai-wrapper is the first AI-friendly API designed to enable planning-based agents to play Dungeon Crawl Stone Soup. In this tutorial we will guide participants through multiple live-coding exercises, providing them with the hands-on experience needed to apply their own custom planning algorithms and techniques to control an agent in DCSS for AI research.</p><h4>Outline</h4><p>The main objective of this tutorial is to provide a hands-on tutorial of the software. By the end of the tutorial, the attendees will be able to install the game / API wrapper, understand various API functionalities, be able to run sample Automated Planning and Reinforcement Learning agents, and understand the experimental metrics that can be used. We propose a 3 hour tutorial with the following schedule.</p><ul><li> <b>-1 week:</b> Provide attendees will setup videos to ensure no day-of configuration issues<li><b>-2 hr to Tutorial Start:</b> Open session to ensure attendeeâ€™s environments are properly configured<li><b>Tutorial Start Time - 30 min:</b> Introductory Lecture to the DCSS Game and the API<li><b>30 min - 1 hr:</b> Learning objective #1 - Get a classical planning agent (using Fastdownward) running in the game<li><b>1.0 hr to 1.5 hr:</b> Learning objective #2 - Obtain and visualize data about the performance of the planning agent against other baseline agents<li><b>1.5 hr to 2.0 hr:</b> Learning objective #3 - Extend the planning agent with more goal types, including attacking monsters and picking up items.<li><b> 2.0 hr - Tutorial End:</b> Extra Credit Exercises:<ul><li> Extend the planning agent with goals and other behaviors to see how far it can travel in the dungeon before dying<li> Customize PDDL knowledge for an alternative planner to FastDownward</ul></ul><h4>Organisers</h4><ul><li> Dr. Dustin Dannenhauer, Parallax Advanced Research Corporation</li><li> Dr. Amos-Binks, ARA</li><li> Dr. Michael Floyd, Knexus Research Corporation</li><li> Dr. Zohreh Dannenhauer, Knexus Research Corporation</li></ul>'},
                    Tutorial2: {name: 'Trustworthy AI: A Computational Perspective',description:'<h4>Description</h4> <p>The past few decades have witnessed the rise of artificial intelligence (AI) technology. However, recent studies show evidence that AI algorithms may not be trustworthy. For example, they could be vulnerable to slight perturbations of input data; they could undermine fairness by showing bias and stereotypes towards certain groups of people; and their decisions could be hard to explain due to their opaque model architectures. With the widespread use of AI applications in our daily life, whether an AI algorithm is trustworthy or not has become a problem of great concern to researchers, developers and users.</p> <p>Recently, a great amount of research on trustworthy AI has emerged. In this tutorial, we aim to provide a comprehensive overview of the cutting-edge research progress on trustworthy AI from a computational perspective. Specifically, we focus on the six most important dimensions in realizing trustworthy AI: (i) Safety & Robustness, (ii) Non-discrimination & Fairness, (iii) Explainability, (iv) Privacy, (v) Accountability & Auditability, and (vi) Environmental Well-Being. We will introduce the latest technologies and real-world applications in each dimension according to a taxonomy, and discuss the accordant and conflicting interactions among various dimensions. Besides, we will discuss potential future research directions in this field.</p> <p>We expect that researchers and practitioners can gain a broad overview and a deep insight of trustworthy AI from this tutorial, so as to advance the progress of this field.</p> <h4> Outline</h4> The tutorial is to be presented as a 3-hour online lecture. <ul> <li> Introduction (10 mins)</li> <li> Dimension I: Safety & Robustness (30 mins),</li> <li> Dimension II: Non-discrimination & Fairness (30 mins),</li> <li> Dimension III: Explainability (30 mins),</li> <li> Dimension IV: Privacy (30 mins),</li> <li> Dimension V: Accountability & Auditability (15 mins),</li> <li> Dimension VI: Environmental Wellbeing (15 mins),</li> <li> Dimension Interactions and Future Directions (20 mins).</li> </ul> <h4>Organisers</h4> <ul> <li> Haochen Liu, Xiaorui Liu, Yaxin Li, Jiliang Tang and Yiqi Wang, Michigan State University</li> <li> Wenqi Fan, Hong Kong Polytechnic University</li> </ul>'}}